# -*- coding: utf-8 -*-
"""Untitled18.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17znI3tCNsOpOSzdvYAJd_kqbyyqkJmax
"""

!pip install numpy==1.23.5 scipy==1.10.1
!sudo apt update
!sudo apt install libcairo2-dev \
    texlive texlive-latex-extra texlive-fonts-extra \
    texlive-latex-recommended texlive-science \
    tipa libpango1.0-dev
!pip install manim
!pip install IPython==8.21.0

pip install numpy==1.23.5 scipy==1.10.1 --force-reinstall

# prompt: write code to find numpy version

import numpy as np
np.__version__

from manim import *

# prompt: mount the drive

from google.colab import drive
drive.mount('/content/drive')

"""#function that is called in end to genrate speak and slide content in manim"""

def generate_manim_code(title, elements):
    code = f"""
from manim import *

class GeneratedScene(MovingCameraScene):
    def get_final_camera_setup(self):
        # Create all mobjects first
        title = Tex(r"{title}", font_size=50).to_edge(UP)
        content_elements = [title]
        prev_mobject = title
"""

    # Generate code for each element
    for idx, elem in enumerate(elements):
        elem_type = elem['type']
        content_lines = elem['content']
        content_args = ", ".join([f'r"{line}"' for line in content_lines])

        # Fix: Use correct class name (Tex/MathTex) instead of TexTex
        class_name = "Tex" if elem_type == "tex" else "MathTex"

        if elem_type == 'tex':
            font_size = 40 if idx < 2 else 36
        else:  # math
            font_size = 40

        code += f"""
        element{idx} = {class_name}({content_args}, font_size={font_size}).next_to(prev_mobject, DOWN, buff=0.5)
        content_elements.append(element{idx})
        prev_mobject = element{idx}
"""

    code += """
        # Group all content elements
        content = VGroup(*content_elements)

        # Initial camera setup with title
        self.add(title)
        title.set_opacity(0)
        self.camera.auto_zoom([title], margin=1)

        # Add content progressively with camera adjustments
        current_content = [title]
        for element in content_elements[1:]:
            self.add(element)
            element.set_opacity(0)
            current_content.append(element)

        # Final adjustment for all content
        self.play(
            self.camera.auto_zoom(
                content,
                margin=0.5,
                animate=True
            ).build(),
            run_time=2
        )
        self.camera.frame.save_state()
        self.camera.auto_zoom(content, margin=0.5)

        # Extract final camera settings
        final_frame_center = self.camera.frame.get_center()
        final_focal_width = self.camera.frame.get_width()

        # Restore initial camera state
        self.camera.frame.restore()

        return final_frame_center, final_focal_width

    def construct(self):
        # Get the final camera position and zoom from the silent run
        final_center, final_width = self.get_final_camera_setup()

        # Create content again for the actual animation
        title = Tex(r"{title}", font_size=50).to_edge(UP)
        content_elements = [title]
        prev_mobject = title
""".format(title=title)

    for idx, elem in enumerate(elements):
        elem_type = elem['type']
        content_lines = elem['content']
        content_args = ", ".join([f'r"{line}"' for line in content_lines])

        # Fix: Use correct class name (Tex/MathTex) instead of TexTex
        class_name = "Tex" if elem_type == "tex" else "MathTex"

        if elem_type == 'tex':
            font_size = 40 if idx < 2 else 36
        else:  # math
            font_size = 40

        code += f"""
        element{idx} = {class_name}({content_args}, font_size={font_size}).next_to(prev_mobject, DOWN, buff=0.5)
        content_elements.append(element{idx})
        prev_mobject = element{idx}
"""

    code += """
        # Group all elements
        content = VGroup(*content_elements)

        # Apply final camera settings before animations start
        self.camera.frame.move_to(final_center)
        self.camera.frame.set_width(final_width)

        # Animate content without camera movement
        self.play(Write(title))
        self.wait(1)
"""

    for idx in range(len(elements)):
        code += f"""
        self.play(Write(element{idx}))
        self.wait(1)
"""

    code += """
        self.wait(2)
"""

    return code



api_key = "AIzaSyDNQ3uLiUTQVljD8Cj5vAAB1HLnk2FQnU4"
# api_key="AIzaSyDt53Vr3SYGKEMAPtGVoH-2OlBpv81ICk8"





from google import genai

client = genai.Client(api_key="AIzaSyDt53Vr3SYGKEMAPtGVoH-2OlBpv81ICk8")

print('My files:')
for f in client.files.list():
  print(" ", f'{f.name}: {f.uri}')



client = genai.Client(api_key="AIzaSyDNQ3uLiUTQVljD8Cj5vAAB1HLnk2FQnU4")
video_file = client.files.get(name="files/gobx18ohlaq7")

"""#pass the video file"""

from google import genai

client = genai.Client(api_key="AIzaSyDNQ3uLiUTQVljD8Cj5vAAB1HLnk2FQnU4")

print("Uploading file...")
video_file = client.files.upload(file="/content/small_vi.mp4")
print(f"Completed upload: {video_file.uri}")

print(video_file)

import time

# Check whether the file is ready to be used.
while video_file.state.name == "PROCESSING":
    print('.', end='')
    time.sleep(1)
    video_file = client.files.get(name=video_file.name)

if video_file.state.name == "FAILED":
  raise ValueError(video_file.state.name)

print('Done')

prompt2vid2text='''This is a video of a teacher explaining mathematical concepts on sheets of paper. Your task is to extract and transcribe the exact content written on each sheet.

Guidelines:

The content may contain complex mathematical symbols, so use LaTeX for proper formatting.

The teacher's hand may partially obscure some parts of the textâ€”do your best to infer but do not create your own content.

Strictly transcribe only what is written, without adding any additional explanations or assumptions.

Provide your response in the following structured format:

Ensure accuracy in transcription and formatting while maintaining the original structure of the content.

Response Format:

Structure the extracted content in the following XML-like format:

<content>
    <slide1>Extracted content from Slide 1</slide1>
    <slide2>Extracted content from Slide 2</slide2>
    <slide3>Extracted content from Slide 3</slide3>
    ...
</content>  '''

client = genai.Client(api_key="AIzaSyDNQ3uLiUTQVljD8Cj5vAAB1HLnk2FQnU4")





print(video_file.name)

from IPython.display import Markdown

# Pass the video file reference like any other media part.
response2 = client.models.generate_content(
    model="gemini-1.5-pro",
    contents=[
        video_file,
        prompt2vid2text])

# Print the response, rendering any Markdown
Markdown(response2.text)

import ast
def convert_string_to_dict(input_str):
    cleaned_str = input_str.strip().strip('`').replace('json\n', '')
    parsed_dict = ast.literal_eval(cleaned_str)

    return {
        "title": parsed_dict["title"],
        "elements": [
            {"type": elem["type"], "content": [item for item in elem["content"]]}
            for elem in parsed_dict["elements"]
        ]
    }

prompt4json="""Write this in the given format only dont write anything else json format only
{
title : "Introduction to Fourier Transform"
elements : [
    {"type": "tex", "content": ["The Fourier Transform decomposes a function"]},
    {"type": "tex", "content": ["into its frequency components."]},
    {"type": "math", "content": [r"F(\omega) = \int_{-\infty}^{\infty} f(t) e^{-i\omega t} dt"]},
    {"type": "tex", "content": ["It is widely used in signal processing."]}
]
}
RETURN your answer in the given format
{
  title: str
  elements: list of dictionary(with key type and content)
}



"""

import re

def extract_slide_content(xml_string):
    """Extracts slide contents from the given XML-like string and returns a list."""
    pattern = re.compile(r'<slide\d+>(.*?)</slide\d+>', re.DOTALL)
    return pattern.findall(xml_string)



l = extract_slide_content(response2.text)
print(l)

prompt="""Write this in the given format only dont write anything else json format only
{
title : "Introduction to Fourier Transform"
elements : [
    {"type": "tex", "content": ["The Fourier Transform decomposes a function"]},
    {"type": "tex", "content": ["into its frequency components."]},
    {"type": "math", "content": [r"F(\omega) = \int_{-\infty}^{\infty} f(t) e^{-i\omega t} dt"]},
    {"type": "tex", "content": ["It is widely used in signal processing."]}
]
}
RETURN your answer in the given format
{
  title: str
  elements: list of dictionary(with key type and content)
}



"""

!pip install manim

from manim import *
from google.colab import drive
import ast
import os

# Mount Google Drive
# drive.mount('/content/drive')

# Define your list l (Replace this with actual values)
# l = ["Example 1", "Example 2", "Example 3"]  # Replace with actual prompts

# Define the folder in Google Drive to save videos
save_folder = "/content/drive/MyDrive/ManimVideos"

# Ensure the folder exists
os.makedirs(save_folder, exist_ok=True)

# Function to convert response text to dictionary
# def convert_string_to_dict(input_str):
#     cleaned_str = input_str.strip().strip('`').replace('json\n', '')
#     parsed_dict = ast.literal_eval(cleaned_str)

#     return {
#         "title": parsed_dict["title"],
#         "elements": [
#             {"type": elem["type"], "content": [item for item in elem["content"]]}
#             for elem in parsed_dict["elements"]
#         ]
#     }

print((l[0]))



print(len(l))

!pip install manim manim-voiceover gtts pydub ffmpeg-python

prompt="""Write this in the given format only dont write anything else json format only
{
title : "Introduction to Fourier Transform"
elements : [
    {"type": "tex", "content": ["The Fourier Transform decomposes a function"],"speak":["The fourier transform decoposes a function "]},
    {"type": "tex", "content": ["into its frequency components."],"speak":["into its frequency components"]},
    {"type": "math", "content": [r"F(\omega) = \int_{-\infty}^{\infty} f(t) e^{-i\omega t} dt"],"speak":["Explain the equation "]},
    {"type": "tex", "content": ["It is widely used in signal processing."],"speak":["It is widely used in signal processing "]}
]
}
RETURN your answer in the given format
{
  title: str
  elements: list of dictionary(with key type content and speak)
}



"""

from manim import *

from google.colab import drive
import ast
import os

# Mount Google Drive
# drive.mount('/content/drive')

# Define your list l (Replace this with actual values)
# l = ["Example 1", "Example 2", "Example 3"]  # Replace with actual prompts

# Define the folder in Google Drive to save videos
save_folder = "/content/drive/MyDrive/ManimVideoFromMP4"

# Ensure the folder exists
os.makedirs(save_folder, exist_ok=True)

# Function to convert response text to dictionary
def convert_string_to_dict(input_str):
    cleaned_str = input_str.strip().strip('`').replace('json\n', '')
    parsed_dict = ast.literal_eval(cleaned_str)

    return {
        "title": parsed_dict["title"],
        "elements": [
            {"type": elem["type"], "content": [item for item in elem["content"]],"speak": [item for item in elem["speak"]]}
            for elem in parsed_dict["elements"]
        ]
    }

# Assuming 'l' is the list you're trying to access

response = client.models.generate_content(model="gemini-2.0-flash", contents=l[1] + "  " + prompt + " ")

response.text

result = convert_string_to_dict(response.text)

# Extract title and elements
title = result["title"]
elements = result["elements"]

for i in elements:
  print(i['content'])
  # print (i['speak'])





"""#genrate manim and overlay voice in it"""

# Commented out IPython magic to ensure Python compatibility.
# # Loop through the list
# %%capture
# !pip install manim manim-voiceover gtts pydub ffmpeg-python
# 
# j=0
# for i in (l):
#     response = client.models.generate_content(
#         model="gemini-2.0-flash",
#         contents=i+"  "+prompt+ " " # Assuming prompt is the text to process
#     )
# 
#     # Convert response to dictionary
#     result = convert_string_to_dict(response.text)
# 
#     # Extract title and elements
#     title = result["title"]
#     elements = result["elements"]
# 
#     print(title,elements , "\n")
#     # Generate Manim code
#     manim_code = generate_manim_code(title, elements)
# 
#     # Save Manim code to a file
#     with open("generated_scene.py", "w") as f:
#         f.write(manim_code)
# 
#     # Run Manim
#     !manim -ql generated_scene.py GeneratedScene
# 
#     # Define a unique video filename
#     video_filename = f"{save_folder}/GeneratedScene_{j}.mp4"
# 
#     # Move the video to Google Drive
#     !mv media/videos/generated_scene/480p15/GeneratedScene.mp4 "{video_filename}"
# 
#     print(f"Saved: {video_filename}")
#     j+=1
#





!pip install yt-dlp

import yt_dlp

def download_audio(youtube_url, output_path="./"):
    ydl_opts = {
        'format': 'bestaudio/best',
        'extract_audio': True,
        'audio_format': 'mp3',
        'outtmpl': f'{output_path}/%(title)s.%(ext)s'
    }

    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        ydl.download([youtube_url])

# Example usage
youtube_link = "https://www.youtube.com/watch?v=nYVig7BfuEA"
download_audio(youtube_link)

